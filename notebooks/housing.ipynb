{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0062fa6e",
   "metadata": {},
   "source": [
    "# Housing Price Modeling (Session 1)\n",
    "\n",
    "This notebook intentionally follows a simple, linear workflow to prepare for refactoring into a production script later. It trains a regression model on `data/housing.csv`, evaluates it, saves the artifact, and shows prediction usage.\n",
    "\n",
    "- Dataset: `data/housing.csv`\n",
    "- Target: `Price`\n",
    "- Model: StandardScaler + SGDRegressor\n",
    "- Metrics: RMSE, RÂ²\n",
    "- Artifacts: `scripts/session_1/housing_linear.joblib`\n",
    "\n",
    "> Next steps (outside this notebook): move logic into `scripts/session_1/train.py` with CLI args and proper logging.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e63313d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 21:07:57,274 INFO housing - Data path: ..\\data\\housing.csv\n",
      "2025-11-08 21:07:57,276 INFO housing - Artifact dir: ..\\scripts\\session_1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s %(levelname)s %(name)s - %(message)s\",\n",
    ")\n",
    "logger = logging.getLogger(\"housing\")\n",
    "\n",
    "# Paths\n",
    "PROJECT_ROOT = Path(\"..\")\n",
    "DATA_PATH = PROJECT_ROOT / \"data\" / \"housing.csv\"\n",
    "ARTIFACT_DIR = PROJECT_ROOT / \"scripts\" / \"session_1\"\n",
    "ARTIFACT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MODEL_PATH = ARTIFACT_DIR / \"housing_linear.joblib\"\n",
    "\n",
    "logger.info(f\"Data path: {DATA_PATH}\")\n",
    "logger.info(f\"Artifact dir: {ARTIFACT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "939d60ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 21:07:58,405 INFO numexpr.utils - NumExpr defaulting to 16 threads.\n",
      "2025-11-08 21:07:59,154 INFO housing - Loading dataset...\n",
      "2025-11-08 21:07:59,192 INFO housing - Loaded 5000 rows and 7 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Avg. Area Income</th>\n",
       "      <th>Avg. Area House Age</th>\n",
       "      <th>Avg. Area Number of Rooms</th>\n",
       "      <th>Avg. Area Number of Bedrooms</th>\n",
       "      <th>Area Population</th>\n",
       "      <th>Price</th>\n",
       "      <th>Address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>79545.45857</td>\n",
       "      <td>5.682861</td>\n",
       "      <td>7.009188</td>\n",
       "      <td>4.09</td>\n",
       "      <td>23086.80050</td>\n",
       "      <td>1.059034e+06</td>\n",
       "      <td>208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>79248.64245</td>\n",
       "      <td>6.002900</td>\n",
       "      <td>6.730821</td>\n",
       "      <td>3.09</td>\n",
       "      <td>40173.07217</td>\n",
       "      <td>1.505891e+06</td>\n",
       "      <td>188 Johnson Views Suite 079\\nLake Kathleen, CA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61287.06718</td>\n",
       "      <td>5.865890</td>\n",
       "      <td>8.512727</td>\n",
       "      <td>5.13</td>\n",
       "      <td>36882.15940</td>\n",
       "      <td>1.058988e+06</td>\n",
       "      <td>9127 Elizabeth Stravenue\\nDanieltown, WI 06482...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63345.24005</td>\n",
       "      <td>7.188236</td>\n",
       "      <td>5.586729</td>\n",
       "      <td>3.26</td>\n",
       "      <td>34310.24283</td>\n",
       "      <td>1.260617e+06</td>\n",
       "      <td>USS Barnett\\nFPO AP 44820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59982.19723</td>\n",
       "      <td>5.040555</td>\n",
       "      <td>7.839388</td>\n",
       "      <td>4.23</td>\n",
       "      <td>26354.10947</td>\n",
       "      <td>6.309435e+05</td>\n",
       "      <td>USNS Raymond\\nFPO AE 09386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Avg. Area Income  Avg. Area House Age  Avg. Area Number of Rooms  \\\n",
       "0       79545.45857             5.682861                   7.009188   \n",
       "1       79248.64245             6.002900                   6.730821   \n",
       "2       61287.06718             5.865890                   8.512727   \n",
       "3       63345.24005             7.188236                   5.586729   \n",
       "4       59982.19723             5.040555                   7.839388   \n",
       "\n",
       "   Avg. Area Number of Bedrooms  Area Population         Price  \\\n",
       "0                          4.09      23086.80050  1.059034e+06   \n",
       "1                          3.09      40173.07217  1.505891e+06   \n",
       "2                          5.13      36882.15940  1.058988e+06   \n",
       "3                          3.26      34310.24283  1.260617e+06   \n",
       "4                          4.23      26354.10947  6.309435e+05   \n",
       "\n",
       "                                             Address  \n",
       "0  208 Michael Ferry Apt. 674\\nLaurabury, NE 3701...  \n",
       "1  188 Johnson Views Suite 079\\nLake Kathleen, CA...  \n",
       "2  9127 Elizabeth Stravenue\\nDanieltown, WI 06482...  \n",
       "3                          USS Barnett\\nFPO AP 44820  \n",
       "4                         USNS Raymond\\nFPO AE 09386  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "logger.info(\"Loading dataset...\")\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "logger.info(f\"Loaded {len(df)} rows and {len(df.columns)} columns\")\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a193965",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 21:08:01,957 INFO housing - Preparing features and target...\n",
      "2025-11-08 21:08:01,967 INFO housing - Splitting train/test...\n",
      "2025-11-08 21:08:01,974 INFO housing - Building pipeline...\n",
      "2025-11-08 21:08:01,976 INFO housing - Training model...\n",
      "2025-11-08 21:08:02,017 INFO housing - Evaluating model...\n",
      "2025-11-08 21:08:02,031 INFO housing - RMSE: 102872.04 | MAE: 82975.05 | R2: 0.9140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 3935343077588.38, NNZs: 5, Bias: -1107588695343.692139, T: 4000, Avg. loss: 139382269725408897395589120.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 3240007814581.78, NNZs: 5, Bias: -260037708623.239014, T: 8000, Avg. loss: 13639750119953053819863040.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 1301182608317.83, NNZs: 5, Bias: 614242133033.577515, T: 12000, Avg. loss: 4647721136717802239950848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1222302686803.81, NNZs: 5, Bias: -812180194301.766479, T: 16000, Avg. loss: 2154838149228694540910592.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1046754575067.95, NNZs: 5, Bias: 488098479823.663208, T: 20000, Avg. loss: 1109073128129765560025088.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 826399656520.77, NNZs: 5, Bias: -72724516714.708893, T: 24000, Avg. loss: 634692571344967053606912.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 399235680176.05, NNZs: 5, Bias: 47986094865.444786, T: 28000, Avg. loss: 346771233836618305503232.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 16979695098.23, NNZs: 5, Bias: -7765677720.910769, T: 32000, Avg. loss: 148788446813696030670848.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 397410.13, NNZs: 5, Bias: 1092863.733973, T: 36000, Avg. loss: 586251872271537668096.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 358275.55, NNZs: 5, Bias: 1158010.088908, T: 40000, Avg. loss: 301327738463.193359\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 377125.70, NNZs: 5, Bias: 1243387.493830, T: 44000, Avg. loss: 27292704443.034691\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 12\n",
      "Norm: 419935.15, NNZs: 5, Bias: 1333722.191379, T: 48000, Avg. loss: 23453764102.642513\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 13\n",
      "Norm: 314679.92, NNZs: 5, Bias: 1248264.485401, T: 52000, Avg. loss: 16585484194.722570\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 14\n",
      "Norm: 347414.10, NNZs: 5, Bias: 1215050.154877, T: 56000, Avg. loss: 14035758376.051027\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 15\n",
      "Norm: 390154.02, NNZs: 5, Bias: 1276741.762782, T: 60000, Avg. loss: 12325600256.893421\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 16\n",
      "Norm: 346695.65, NNZs: 5, Bias: 1258579.692416, T: 64000, Avg. loss: 11378942525.306496\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 17\n",
      "Norm: 328568.39, NNZs: 5, Bias: 1207214.773111, T: 68000, Avg. loss: 10992045984.009232\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 18\n",
      "Norm: 385797.59, NNZs: 5, Bias: 1232054.178845, T: 72000, Avg. loss: 9706397071.616760\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 19\n",
      "Norm: 418514.63, NNZs: 5, Bias: 1242604.423583, T: 76000, Avg. loss: 9254349531.268414\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 20\n",
      "Norm: 392154.58, NNZs: 5, Bias: 1212260.976722, T: 80000, Avg. loss: 8988463656.953644\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 21\n",
      "Norm: 384140.88, NNZs: 5, Bias: 1231538.582964, T: 84000, Avg. loss: 8560154673.196988\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 22\n",
      "Norm: 392487.30, NNZs: 5, Bias: 1218986.484465, T: 88000, Avg. loss: 8162785903.842529\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 23\n",
      "Norm: 353099.93, NNZs: 5, Bias: 1203857.540588, T: 92000, Avg. loss: 8155876512.090563\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 24\n",
      "Norm: 370384.17, NNZs: 5, Bias: 1235498.171686, T: 96000, Avg. loss: 7820308473.065305\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 25\n",
      "Norm: 296332.89, NNZs: 5, Bias: 1220051.353415, T: 100000, Avg. loss: 7485877410.457940\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 26\n",
      "Norm: 413292.35, NNZs: 5, Bias: 1201176.219872, T: 104000, Avg. loss: 7491523724.291194\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 27\n",
      "Norm: 357526.21, NNZs: 5, Bias: 1238077.358621, T: 108000, Avg. loss: 7244516421.359512\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 28\n",
      "Norm: 348787.53, NNZs: 5, Bias: 1231901.215394, T: 112000, Avg. loss: 7192412839.793638\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 29\n",
      "Norm: 401498.84, NNZs: 5, Bias: 1243338.503019, T: 116000, Avg. loss: 7207955847.895856\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 30\n",
      "Norm: 361421.15, NNZs: 5, Bias: 1265696.785047, T: 120000, Avg. loss: 7063615303.260292\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 31\n",
      "Norm: 361814.44, NNZs: 5, Bias: 1188770.732684, T: 124000, Avg. loss: 6936214170.316066\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 32\n",
      "Norm: 365933.96, NNZs: 5, Bias: 1258526.418121, T: 128000, Avg. loss: 6933778646.809788\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 33\n",
      "Norm: 370778.40, NNZs: 5, Bias: 1208169.982211, T: 132000, Avg. loss: 6798167613.712378\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 34\n",
      "Norm: 343887.18, NNZs: 5, Bias: 1251829.656509, T: 136000, Avg. loss: 6728170840.730910\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 35\n",
      "Norm: 349344.50, NNZs: 5, Bias: 1264030.593616, T: 140000, Avg. loss: 6647423974.817153\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 36\n",
      "Norm: 347412.51, NNZs: 5, Bias: 1238198.571966, T: 144000, Avg. loss: 6752340973.483287\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 37\n",
      "Norm: 366717.31, NNZs: 5, Bias: 1208970.428945, T: 148000, Avg. loss: 6607815899.055364\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 38\n",
      "Norm: 343923.02, NNZs: 5, Bias: 1237314.255989, T: 152000, Avg. loss: 6545965418.671225\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 39\n",
      "Norm: 327409.35, NNZs: 5, Bias: 1220489.960658, T: 156000, Avg. loss: 6547982627.807577\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 40\n",
      "Norm: 346129.57, NNZs: 5, Bias: 1229910.732229, T: 160000, Avg. loss: 6458839603.173979\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 41\n",
      "Norm: 323451.30, NNZs: 5, Bias: 1220280.052451, T: 164000, Avg. loss: 6454325942.929235\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 42\n",
      "Norm: 364787.17, NNZs: 5, Bias: 1247516.369255, T: 168000, Avg. loss: 6372179212.402203\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 43\n",
      "Norm: 311160.91, NNZs: 5, Bias: 1259693.302565, T: 172000, Avg. loss: 6293345035.024585\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 44\n",
      "Norm: 321721.01, NNZs: 5, Bias: 1248763.190696, T: 176000, Avg. loss: 6143020510.042522\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 45\n",
      "Norm: 356296.95, NNZs: 5, Bias: 1224903.173261, T: 180000, Avg. loss: 6304309115.979200\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 46\n",
      "Norm: 375176.09, NNZs: 5, Bias: 1218144.388925, T: 184000, Avg. loss: 6279038705.196695\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 47\n",
      "Norm: 302279.60, NNZs: 5, Bias: 1229148.984197, T: 188000, Avg. loss: 6183554858.939042\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 48\n",
      "Norm: 340550.23, NNZs: 5, Bias: 1215507.339936, T: 192000, Avg. loss: 6121749810.678827\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 49\n",
      "Norm: 348249.42, NNZs: 5, Bias: 1204301.075633, T: 196000, Avg. loss: 6112330010.069599\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 50\n",
      "Norm: 338806.61, NNZs: 5, Bias: 1208588.772383, T: 200000, Avg. loss: 6069886956.598984\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 51\n",
      "Norm: 347474.24, NNZs: 5, Bias: 1227078.608051, T: 204000, Avg. loss: 6044112026.326440\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 52\n",
      "Norm: 342008.20, NNZs: 5, Bias: 1236158.329511, T: 208000, Avg. loss: 6141922150.367671\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 53\n",
      "Norm: 325874.78, NNZs: 5, Bias: 1222419.292663, T: 212000, Avg. loss: 6024982451.813216\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 54\n",
      "Norm: 331443.86, NNZs: 5, Bias: 1228030.349895, T: 216000, Avg. loss: 6029940293.092259\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 55\n",
      "Norm: 333272.45, NNZs: 5, Bias: 1247597.769595, T: 220000, Avg. loss: 5996263804.857689\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 56\n",
      "Norm: 337750.49, NNZs: 5, Bias: 1215641.825879, T: 224000, Avg. loss: 5989403831.594965\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 57\n",
      "Norm: 365888.80, NNZs: 5, Bias: 1240968.455196, T: 228000, Avg. loss: 6030426617.678018\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 58\n",
      "Norm: 373390.78, NNZs: 5, Bias: 1219474.212360, T: 232000, Avg. loss: 5926106703.656730\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 59\n",
      "Norm: 346910.48, NNZs: 5, Bias: 1203532.004403, T: 236000, Avg. loss: 5971239562.207822\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 60\n",
      "Norm: 377145.43, NNZs: 5, Bias: 1223648.370237, T: 240000, Avg. loss: 5940687311.707108\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 61\n",
      "Norm: 355653.01, NNZs: 5, Bias: 1198292.914396, T: 244000, Avg. loss: 5888957071.994823\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 62\n",
      "Norm: 360212.29, NNZs: 5, Bias: 1238109.991821, T: 248000, Avg. loss: 5896901037.186298\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 63\n",
      "Norm: 356017.77, NNZs: 5, Bias: 1205641.877410, T: 252000, Avg. loss: 5794181055.914899\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 64\n",
      "Norm: 357249.23, NNZs: 5, Bias: 1223921.451116, T: 256000, Avg. loss: 5776375520.344287\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 65\n",
      "Norm: 351595.10, NNZs: 5, Bias: 1235662.988486, T: 260000, Avg. loss: 5859525902.970682\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 66\n",
      "Norm: 365164.84, NNZs: 5, Bias: 1228987.141474, T: 264000, Avg. loss: 5771860140.436581\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 67\n",
      "Norm: 351668.28, NNZs: 5, Bias: 1212864.684741, T: 268000, Avg. loss: 5855088826.786493\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 68\n",
      "Norm: 337059.07, NNZs: 5, Bias: 1233104.264734, T: 272000, Avg. loss: 5791729098.418013\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 69\n",
      "Norm: 353661.11, NNZs: 5, Bias: 1220643.631279, T: 276000, Avg. loss: 5831657463.143980\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 70\n",
      "Norm: 347709.60, NNZs: 5, Bias: 1244927.693154, T: 280000, Avg. loss: 5781000316.402091\n",
      "Total training time: 0.02 seconds.\n",
      "-- Epoch 71\n",
      "Norm: 343419.74, NNZs: 5, Bias: 1237910.452273, T: 284000, Avg. loss: 5796584204.199292\n",
      "Total training time: 0.02 seconds.\n",
      "Convergence after 71 epochs took 0.02 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(np.float64(102872.04304935804), 82975.0466981154, 0.9139848314596221)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "logger.info(\"Preparing features and target...\")\n",
    "# Identify target and basic features from the CSV header\n",
    "TARGET = \"Price\"\n",
    "ALL_COLUMNS = df.columns.tolist()\n",
    "NUM_FEATURES = [\n",
    "    \"Avg. Area Income\",\n",
    "    \"Avg. Area House Age\",\n",
    "    \"Avg. Area Number of Rooms\",\n",
    "    \"Avg. Area Number of Bedrooms\",\n",
    "    \"Area Population\",\n",
    "]\n",
    "CAT_FEATURES = [\n",
    "    # 'Address' exists but is high-cardinality; we'll drop it for a simple baseline\n",
    "]\n",
    "\n",
    "X = df[NUM_FEATURES]\n",
    "y = df[TARGET]\n",
    "\n",
    "logger.info(\"Splitting train/test...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "logger.info(\"Building pipeline...\")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", StandardScaler(), NUM_FEATURES),\n",
    "        # (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CAT_FEATURES),\n",
    "    ],\n",
    "    remainder=\"drop\",\n",
    ")\n",
    "\n",
    "model = Pipeline(\n",
    "    steps=[\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"regressor\", SGDRegressor(\n",
    "            max_iter=5000,\n",
    "            tol=1e-4,\n",
    "            learning_rate=\"optimal\",\n",
    "            random_state=42,\n",
    "            verbose=1\n",
    "        )),\n",
    "    ]\n",
    ")\n",
    "\n",
    "logger.info(\"Training model...\")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "logger.info(\"Evaluating model...\")\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "logger.info(f\"RMSE: {rmse:.2f} | MAE: {mae:.2f} | R2: {r2:.4f}\")\n",
    "\n",
    "rmse, mae, r2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbf81496",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 21:08:02,056 INFO housing - Saving model to ..\\scripts\\session_1\\housing_linear.joblib ...\n",
      "2025-11-08 21:08:02,066 INFO housing - Model saved.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WindowsPath('../scripts/session_1/housing_linear.joblib')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "logger.info(f\"Saving model to {MODEL_PATH} ...\")\n",
    "joblib.dump(model, MODEL_PATH)\n",
    "logger.info(\"Model saved.\")\n",
    "\n",
    "MODEL_PATH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8aca3fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-08 21:08:02,092 INFO housing - Predicting with in-memory model...\n",
      "2025-11-08 21:08:02,107 INFO housing - Reloading model from disk and predicting...\n",
      "2025-11-08 21:08:02,116 INFO housing - Comparing predictions (should match closely):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred_in_memory</th>\n",
       "      <th>pred_loaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.323582e+06</td>\n",
       "      <td>1.323582e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.256339e+06</td>\n",
       "      <td>1.256339e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.301581e+06</td>\n",
       "      <td>1.301581e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.251606e+06</td>\n",
       "      <td>1.251606e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.069425e+06</td>\n",
       "      <td>1.069425e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pred_in_memory   pred_loaded\n",
       "0    1.323582e+06  1.323582e+06\n",
       "1    1.256339e+06  1.256339e+06\n",
       "2    1.301581e+06  1.301581e+06\n",
       "3    1.251606e+06  1.251606e+06\n",
       "4    1.069425e+06  1.069425e+06"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Demonstrate predictions using the trained pipeline and after reload\n",
    "import numpy as np\n",
    "\n",
    "# Create a small batch from X_test\n",
    "sample = X_test.iloc[:5]\n",
    "logger.info(\"Predicting with in-memory model...\")\n",
    "preds_in_memory = model.predict(sample)\n",
    "\n",
    "logger.info(\"Reloading model from disk and predicting...\")\n",
    "loaded = joblib.load(MODEL_PATH)\n",
    "preds_loaded = loaded.predict(sample)\n",
    "\n",
    "logger.info(\"Comparing predictions (should match closely):\")\n",
    "comparison = pd.DataFrame({\n",
    "    \"pred_in_memory\": preds_in_memory,\n",
    "    \"pred_loaded\": preds_loaded,\n",
    "})\n",
    "comparison\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
